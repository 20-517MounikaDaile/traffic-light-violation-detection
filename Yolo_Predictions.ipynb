{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebabc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract as pt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8fddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "INPUT_WIDTH =  640\n",
    "INPUT_HEIGHT = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691e6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c4e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 1, 2 2s, 1 5, 1 6, 1 7, 1 A, 1 B, 1 H, 1 WPLATE, 4464.5ms\n",
      "Speed: 197.1ms preprocess, 4464.5ms inference, 359.8ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# loading a custom model\n",
    "model = YOLO('numberplate.pt')\n",
    "image = cv2.imread('./test_images/im2.jpg')\n",
    "cv2.imshow('img',image)\n",
    "results = model.predict(image,imgsz=640,conf=0.25,iou=0.45)\n",
    "results = results[0]  \n",
    "s=\"\"\n",
    "for i in range(len(results.boxes)):\n",
    "    box = results.boxes[i]\n",
    "    tensor = box.xyxy[0]\n",
    "    x1 = int(tensor[0].item())\n",
    "    y1 = int(tensor[1].item())\n",
    "    x2 = int(tensor[2].item())\n",
    "    y2 = int(tensor[3].item())\n",
    "    cv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc2d130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07f4c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\signal1.jpg: 480x800 1 light, 1 red, 3484.1ms\n",
      "Speed: 348.1ms preprocess, 3484.1ms inference, 593.7ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1080.974609375, 151.411376953125, 1255.3118896484375, 671.8123168945312], [1105.99951171875, 177.7313232421875, 1219.149658203125, 304.62158203125]]\n",
      "1.0 light 1080.974609375 151.411376953125 1255.3118896484375 671.8123168945312\n",
      "1080 151 1255 671\n",
      "2.0 red 1105.99951171875 177.7313232421875 1219.149658203125 304.62158203125\n",
      "1105 177 1219 304\n",
      "['light', 'red']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"trafficlight.pt\")  \n",
    "results = model('./test_images/signal1.jpg') \n",
    "image=cv2.imread('./test_images/signal1.jpg')\n",
    "cv2.resize(image, (300,300))\n",
    " # return a list of Results objects\n",
    "labels=[]\n",
    "# Process results list\n",
    "l=[]\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "    print(boxes)\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        name = names[int(cls)]\n",
    "        x1=int(x1)\n",
    "        x2=int(x2)\n",
    "        y1=int(y1)\n",
    "        y2=int(y2)\n",
    "        l.append(name)\n",
    "        print(x1,y1,x2,y2)\n",
    "        \n",
    "        img=cv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3) \n",
    "print(l)\n",
    "cv2.imshow('images',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f84432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\im1.jpg: 416x640 1 3, 3 4s, 1 9, 1 A, 1 C, 1 D, 1 F, 1 L, 1 WPLATE, 2676.9ms\n",
      "Speed: 6.0ms preprocess, 2676.9ms inference, 93.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Sorted Classes:\n",
      "Class: WPLATE, x1: 38\n",
      "Class: D, x1: 78\n",
      "Class: L, x1: 117\n",
      "Class: 4, x1: 156\n",
      "Class: C, x1: 194\n",
      "Class: A, x1: 232\n",
      "Class: F, x1: 269\n",
      "Class: 4, x1: 307\n",
      "Class: 9, x1: 346\n",
      "Class: 4, x1: 383\n",
      "Class: 3, x1: 421\n",
      "DL4CAF4943\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"numberplate.pt\")  \n",
    "image=cv2.imread('./test_images/im1.jpg')\n",
    "results = model('./test_images/im1.jpg')  # return a list of Results objects\n",
    "detected_objects = []\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        name = names[int(cls)]\n",
    "        x1 = int(x1)\n",
    "        x2 = int(x2)\n",
    "        y1 = int(y1)\n",
    "        y2 = int(y2)\n",
    "\n",
    "        # Append class name and x1 coordinate to the list\n",
    "        detected_objects.append({'class': name, 'x1': x1})\n",
    "\n",
    "        # Draw bounding box on the image\n",
    "        img = cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "# Sort the list based on x1 coordinates\n",
    "sorted_objects = sorted(detected_objects, key=lambda x: x['x1'])\n",
    "str1=\"\"\n",
    "# Print sorted classes\n",
    "print(\"Sorted Classes:\")\n",
    "for obj in sorted_objects:\n",
    "    print(f\"Class: {obj['class']}, x1: {obj['x1']}\")\n",
    "    if obj['class']!=\"WPLATE\":\n",
    "      str1=str1+obj['class']\n",
    "print(str1)\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow('images',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"vehicle_detect.pt\")  \n",
    "image=cv2.imread('./test_images/imageso2.jpg')\n",
    "cv2.resize(image, (300,300))\n",
    "results = model('./test_images/imageso2.jpg')  # return a list of Results objects\n",
    "labels=[]\n",
    "print(results)\n",
    "# Process results list\n",
    "l=[]\n",
    "\n",
    "for result in results:\n",
    "    \n",
    "    \n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "    print(\"BOXES is>>>>>>>>>>>>>>>>>>>>>>>>>>..\")\n",
    "    print(boxes)\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        print(\"BOX IS>>>>>>>>>>>>>>>\")\n",
    "        print(box)\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        name = names[int(cls)]\n",
    "        x1=int(x1)\n",
    "        x2=int(x2)\n",
    "        y1=int(y1)\n",
    "        y2=int(y2)\n",
    "        print(\"BOUNDING BOXES>>>>>>>>>>>>>>....\")\n",
    "        print(x1,y1,x2,y2)\n",
    "        l.append(name)\n",
    "        \n",
    "        \n",
    "        img=cv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3) \n",
    "print(l)\n",
    "cv2.imshow('images',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c548ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\im5.jpg: 800x384 1 plate, 953.0ms\n",
      "Speed: 7.3ms preprocess, 953.0ms inference, 15.6ms postprocess per image at shape (1, 3, 800, 384)\n",
      "[[191.35903930664062, 813.8946533203125, 363.3692932128906, 851.7979736328125]]\n",
      "0.0 plate 191.35903930664062 813.8946533203125 363.3692932128906 851.7979736328125\n",
      "191 813 363 851\n",
      "['plate']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"plates.pt\")  \n",
    "image=cv2.imread('./test_images/im5.jpg')\n",
    "cv2.resize(image, (300,300))\n",
    "results = model('./test_images/im5.jpg')  # return a list of Results objects\n",
    "labels=[]\n",
    "# Process results list\n",
    "l=[]\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "    print(boxes)\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        name = names[int(cls)]\n",
    "        x1=int(x1)\n",
    "        x2=int(x2)\n",
    "        y1=int(y1)\n",
    "        y2=int(y2)\n",
    "        l.append(name)\n",
    "        print(x1,y1,x2,y2)\n",
    "        \n",
    "        img=cv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3) \n",
    "print(l)\n",
    "cv2.imshow('images',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dba39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE IMAGE\n",
    "img = cv2.imread('./test_images/im5.jpg')\n",
    "\n",
    "cv2.namedWindow('test image',cv2.WINDOW_KEEPRATIO)\n",
    "cv2.imshow('test image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922f0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD YOLO MODEL\n",
    "net = cv2.dnn.readNetFromONNX('./weights/best.onnx')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced4365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18794a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colour_name(R,G,B):\n",
    "    minimum=10000\n",
    "    index=[\"colour\",\"colour_name\",\"hex\",\"R\",\"G\",\"B\"]\n",
    "    csv=pandas.read_csv('colors.csv',names=index,header=None)\n",
    "    for i in range(len(csv)):\n",
    "        d=abs(R-int(csv.loc[i,\"R\"]))+abs(G-int(csv.loc[i,\"G\"]))+abs(B-int(csv.loc[i,\"B\"]))\n",
    "        if d<=minimum:\n",
    "            minimum=d\n",
    "            cname=csv.loc[i,\"colour_name\"]\n",
    "    return cname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ace7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[\"colour\",\"colour_name\",\"hex\",\"R\",\"G\",\"B\"]\n",
    "csv=pandas.read_csv('colors.csv',names=index,header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b586451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colour</th>\n",
       "      <th>colour_name</th>\n",
       "      <th>hex</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_force_blue_raf</td>\n",
       "      <td>Air Force Blue (Raf)</td>\n",
       "      <td>#5d8aa8</td>\n",
       "      <td>93</td>\n",
       "      <td>138</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_force_blue_usaf</td>\n",
       "      <td>Air Force Blue (Usaf)</td>\n",
       "      <td>#00308f</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_superiority_blue</td>\n",
       "      <td>Air Superiority Blue</td>\n",
       "      <td>#72a0c1</td>\n",
       "      <td>114</td>\n",
       "      <td>160</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabama_crimson</td>\n",
       "      <td>Alabama Crimson</td>\n",
       "      <td>#a32638</td>\n",
       "      <td>163</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alice_blue</td>\n",
       "      <td>Alice Blue</td>\n",
       "      <td>#f0f8ff</td>\n",
       "      <td>240</td>\n",
       "      <td>248</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>yellow_orange</td>\n",
       "      <td>Yellow Orange</td>\n",
       "      <td>#ffae42</td>\n",
       "      <td>255</td>\n",
       "      <td>174</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>yellow_process</td>\n",
       "      <td>Yellow (Process)</td>\n",
       "      <td>#ffef00</td>\n",
       "      <td>255</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>yellow_ryb</td>\n",
       "      <td>Yellow (Ryb)</td>\n",
       "      <td>#fefe33</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>zaffre</td>\n",
       "      <td>Zaffre</td>\n",
       "      <td>#0014a8</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>zinnwaldite_brown</td>\n",
       "      <td>Zinnwaldite Brown</td>\n",
       "      <td>#2c1608</td>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   colour            colour_name      hex    R    G    B\n",
       "0      air_force_blue_raf   Air Force Blue (Raf)  #5d8aa8   93  138  168\n",
       "1     air_force_blue_usaf  Air Force Blue (Usaf)  #00308f    0   48  143\n",
       "2    air_superiority_blue   Air Superiority Blue  #72a0c1  114  160  193\n",
       "3         alabama_crimson        Alabama Crimson  #a32638  163   38   56\n",
       "4              alice_blue             Alice Blue  #f0f8ff  240  248  255\n",
       "..                    ...                    ...      ...  ...  ...  ...\n",
       "860         yellow_orange          Yellow Orange  #ffae42  255  174   66\n",
       "861        yellow_process       Yellow (Process)  #ffef00  255  239    0\n",
       "862            yellow_ryb           Yellow (Ryb)  #fefe33  254  254   51\n",
       "863                zaffre                 Zaffre  #0014a8    0   20  168\n",
       "864     zinnwaldite_brown      Zinnwaldite Brown  #2c1608   44   22    8\n",
       "\n",
       "[865 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68667c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_update_vehicle(csv_file, number_plate, vehicle_name):\n",
    "    rows = []\n",
    "    row_found = False\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(csv_file):\n",
    "        # Read existing data\n",
    "        with open(csv_file, 'r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "        \n",
    "            # Check if the vehicle already exists\n",
    "            if len(rows)==0:\n",
    "                if len(number_plate)!=0:\n",
    "                \n",
    "                    rows.append([number_plate, vehicle_name, '1'])\n",
    "                \n",
    "            else:\n",
    "                rows = list(reader)\n",
    "                if len(number_plate)!=0:\n",
    "                    for row in rows:\n",
    "                        if row[0] == number_plate and row[1] == vehicle_name:\n",
    "                            row[2] = str(int(row[2]) + 1)  # Increment count\n",
    "                            row_found = True\n",
    "                            break\n",
    "\n",
    "    # If the vehicle doesn't exist, add it\n",
    "    if not row_found:\n",
    "        rows.append([number_plate, vehicle_name, '1'])\n",
    "\n",
    "    # Write back to the CSV file\n",
    "    with open(csv_file, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd8430da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections(img,net):\n",
    "    # CONVERT IMAGE TO YOLO FORMAT\n",
    "    image = img.copy()\n",
    "    row, col, d = image.shape\n",
    "\n",
    "    max_rc = max(row,col)\n",
    "    input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "    input_image[0:row,0:col] = image\n",
    "\n",
    "    # GET PREDICTION FROM YOLO MODEL\n",
    "    blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WIDTH,INPUT_HEIGHT),swapRB=True,crop=False)\n",
    "    net.setInput(blob)\n",
    "    preds = net.forward()\n",
    "    detections = preds[0]\n",
    "    return input_image, detections\n",
    "\n",
    "def non_maximum_supression(input_image,detections):\n",
    "    # FILTER DETECTIONS BASED ON CONFIDENCE AND PROBABILIY SCORE\n",
    "    # center x, center y, w , h, conf, proba\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "\n",
    "    image_w, image_h = input_image.shape[:2]\n",
    "    x_factor = image_w/INPUT_WIDTH\n",
    "    y_factor = image_h/INPUT_HEIGHT\n",
    "\n",
    "    for i in range(len(detections)):\n",
    "        row = detections[i]\n",
    "        confidence = row[4] # confidence of detecting license plate\n",
    "        if confidence > 0.05:\n",
    "            class_score = row[5] # probability score of license plate\n",
    "            if class_score > 0.1:\n",
    "                cx, cy , w, h = row[0:4]\n",
    "\n",
    "                left = int((cx - 0.5*w)*x_factor)\n",
    "                top = int((cy-0.5*h)*y_factor)\n",
    "                width = int(w*x_factor)\n",
    "                height = int(h*y_factor)\n",
    "                box = np.array([left,top,width,height])\n",
    "\n",
    "                confidences.append(confidence)\n",
    "                boxes.append(box)\n",
    "\n",
    "    # clean\n",
    "    boxes_np = np.array(boxes).tolist()\n",
    "    confidences_np = np.array(confidences).tolist()\n",
    "    # NMS\n",
    "    index = np.array(cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45)).flatten()\n",
    "    \n",
    "    return boxes_np, confidences_np, index\n",
    "\n",
    "def drawings(image,boxes_np,confidences_np,index,model,nam):\n",
    "    allt=[]\n",
    "    # drawings\n",
    "    for ind in index:\n",
    "        x,y,w,h =  boxes_np[ind]\n",
    "        bb_conf = confidences_np[ind]\n",
    "        conf_text = 'plate: {:.0f}%'.format(bb_conf*100)\n",
    "        license_text = extract_text(image,boxes_np[ind])\n",
    "        \n",
    "        s=\"\"\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        cv2.imwrite('plate.jpg',roi)\n",
    "        imag=cv2.imread(\"plate.jpg\")\n",
    "        \n",
    "        results = model(imag) # return a list of Results objects\n",
    "        detected_objects = []\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.tolist()\n",
    "            classes = result.boxes.cls.tolist()\n",
    "            names = result.names\n",
    "            confidences = result.boxes.conf.tolist()\n",
    "\n",
    "            for box, cls, conf in zip(boxes, classes, confidences):\n",
    "                x1, y1, x2, y2 = box\n",
    "                confidence = conf\n",
    "                detected_class = cls\n",
    "                name = names[int(cls)]\n",
    "                x1 = int(x1)\n",
    "                x2 = int(x2)\n",
    "                y1 = int(y1)\n",
    "                y2 = int(y2)\n",
    "\n",
    "                # Append class name and x1 coordinate to the list\n",
    "                detected_objects.append({'class': name, 'x1': x1})\n",
    "\n",
    "                # Draw bounding box on the image\n",
    "                img = cv2.rectangle(imag, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "# Sort the list based on x1 coordinates\n",
    "        sorted_objects = sorted(detected_objects, key=lambda z: z['x1'])\n",
    "        str1=\"\"\n",
    "        # Print sorted classes\n",
    "        for obj in sorted_objects:\n",
    "            \n",
    "            if obj['class']!=\"WPLATE\" and obj['class']!=\"RPLATE\":\n",
    "              str1=str1+obj['class']\n",
    "              print(str1)\n",
    "        print(str1)\n",
    "        \n",
    "\n",
    "\n",
    "# Example usage\n",
    "        csv_file =\"file.csv\"\n",
    "\n",
    "        add_or_update_vehicle(csv_file, str1, nam)\n",
    "\n",
    "        # Display the image with bounding boxes\n",
    "        \n",
    "        \n",
    "        print(license_text,end=\" \")\n",
    "        print(s)\n",
    "        t=[x,y,w,h]\n",
    "        r=g=b=x_pos=y_pos=0\n",
    "        index=[\"colour\",\"colour_name\",\"hex\",\"R\",\"G\",\"B\"]\n",
    "        csv=pandas.read_csv('colors.csv',names=index,header=None)\n",
    "        allt.append(t)\n",
    "\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a06d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "def dr(image,boxes_np,confidences_np,index):\n",
    "    # drawings\n",
    "    for ind in index:\n",
    "        x,y,w,h =  boxes_np[ind]\n",
    "        bb_conf = confidences_np[ind]\n",
    "        conf_text = 'plate: {:.0f}%'.format(bb_conf*100)\n",
    "        license_text = extract_text(image,boxes_np[ind])\n",
    "        l.append(license_text)\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73512cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f536e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yolo_predictions(img,net,model,nam):\n",
    "    ## step-1: detections\n",
    "    input_image, detections = get_detections(img,net)\n",
    "    ## step-2: NMS\n",
    "    boxes_np, confidences_np, index = non_maximum_supression(input_image, detections)\n",
    "    ## step-3: Drawings\n",
    "    result_img= drawings(img,boxes_np,confidences_np,index,model,nam)\n",
    "\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18018486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c633de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text(image,bbox):\n",
    "    res=[]\n",
    "    x,y,w,h = bbox\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    \n",
    "    if 0 in roi.shape:\n",
    "        return ''\n",
    "    \n",
    "    else:\n",
    "        text = pt.image_to_string(roi)\n",
    "        text = text.strip()\n",
    "        res.append(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98786f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\signal4.jpg: 544x800 1 light, 1398.3ms\n",
      "Speed: 14.5ms preprocess, 1398.3ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 800)\n",
      "[[28.58917808532715, 4.443793296813965, 50.42734146118164, 51.837852478027344]]\n",
      "1.0 light 28.58917808532715 4.443793296813965 50.42734146118164 51.837852478027344\n",
      "28 4 50 51\n",
      "['light']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"trafficlight.pt\")  \n",
    "results = model('./test_images/signal4.jpg') \n",
    "image=cv2.imread('./test_images/signal4.jpg')\n",
    "cv2.resize(image, (300,300)) # return a list of Results objects\n",
    "labels=[]\n",
    "# Process results list\n",
    "lights=[]\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "    print(boxes)\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        name = names[int(cls)]\n",
    "        x1=int(x1)\n",
    "        x2=int(x2)\n",
    "        y1=int(y1)\n",
    "        y2=int(y2)\n",
    "        lights.append(name)\n",
    "        print(x1,y1,x2,y2)\n",
    "        img=cv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3) \n",
    "cv2.imshow(\"imagee1\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58cd822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light():\n",
    "    model = YOLO(\"trafficlight.pt\")  \n",
    "    results = model('./test_images/signal4.jpg') \n",
    "    image=cv2.imread('./test_images/signal4.jpg')\n",
    "    cv2.resize(image, (300,300)) # return a list of Results objects\n",
    "    labels=[]\n",
    "    # Process results list\n",
    "    lights=[]\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.tolist()\n",
    "        classes = result.boxes.cls.tolist()\n",
    "        names = result.names\n",
    "        confidences = result.boxes.conf.tolist()\n",
    "        print(boxes)\n",
    "        for box, cls, conf in zip(boxes, classes, confidences):\n",
    "            x1, y1, x2, y2 = box\n",
    "            print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "            confidence = conf\n",
    "            detected_class = cls\n",
    "            name = names[int(cls)]\n",
    "            x1=int(x1)\n",
    "            x2=int(x2)\n",
    "            y1=int(y1)\n",
    "            y2=int(y2)\n",
    "            lights.append(name)\n",
    "            print(x1,y1,x2,y2)\n",
    "    return lights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32bd8fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\signal4.jpg: 544x800 1 zebra, 1282.3ms\n",
      "Speed: 11.0ms preprocess, 1282.3ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 800)\n",
      "[[39.181793212890625, 129.61654663085938, 273.35498046875, 183.0]]\n",
      "0.0 zebra 39.181793212890625 129.61654663085938 273.35498046875 183.0\n",
      "39 129 273 183\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"zebracross.pt\")  \n",
    "results = model('./test_images/signal4.jpg') \n",
    "image=cv2.imread('./test_images/signal4.jpg')\n",
    "cv2.resize(image, (300,300))\n",
    " # return a list of Results objects\n",
    "labels=[]\n",
    "# Process results list\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "    print(boxes)\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        name = names[int(cls)]\n",
    "        x1=int(x1)\n",
    "        x2=int(x2)\n",
    "        y1=int(y1)\n",
    "        y2=int(y2)\n",
    "        \n",
    "        print(x1,y1,x2,y2)\n",
    "        zebra=[]\n",
    "        zebra.append(x1)\n",
    "        zebra.append(x2)\n",
    "        zebra.append(y1)\n",
    "        zebra.append(y2)\n",
    "        \n",
    "        img=cv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3) \n",
    "cv2.imshow(\"imagee1\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08e1a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4ea6d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\signal4.jpg: 544x800 1 car, 1260.5ms\n",
      "Speed: 11.4ms preprocess, 1260.5ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 800)\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\test_images\\signal4.jpg: 544x800 1 light, 820.9ms\n",
      "Speed: 10.9ms preprocess, 820.9ms inference, 15.6ms postprocess per image at shape (1, 3, 544, 800)\n",
      "[[28.58917808532715, 4.443793296813965, 50.42734146118164, 51.837852478027344]]\n",
      "1.0 light 28.58917808532715 4.443793296813965 50.42734146118164 51.837852478027344\n",
      "28 4 50 51\n",
      "['light']\n",
      "[[106.75444793701172, 106.26177978515625, 154.341796875, 139.58908081054688]]\n",
      "3.0 car 106.75444793701172 106.26177978515625 154.341796875 139.58908081054688\n",
      "106 106 154 139\n",
      "['light']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "model1 = YOLO(\"veh.pt\") \n",
    "model = YOLO(\"numberplate.pt\")\n",
    "zebra= YOLO(\"zebracross.pt\")\n",
    "results = model1('./test_images/signal4.jpg') \n",
    "# return a list of Results objects\n",
    "image=cv2.imread('./test_images/signal4.jpg')\n",
    "labels=[]\n",
    "# Process results list\n",
    "l=[]\n",
    "lights=light()\n",
    "print(lights)\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.tolist()\n",
    "    classes = result.boxes.cls.tolist()\n",
    "    names = result.names\n",
    "    confidences = result.boxes.conf.tolist()\n",
    "    print(boxes)\n",
    "    for box, cls, conf in zip(boxes, classes, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "        confidence = conf\n",
    "        detected_class = cls\n",
    "        nam = names[int(cls)]\n",
    "        \n",
    "        x1=int(x1)#x\n",
    "        x2=int(x2)#y\n",
    "        y1=int(y1)#w\n",
    "        y2=int(y2)#h\n",
    "        l.append(nam)\n",
    "        print(x1,y1,x2,y2)\n",
    "        roi = image[x2+10:x2+y2+10, x1+10:x1+y1+10]\n",
    "        print(lights)\n",
    "        if 'red' in lights:\n",
    "            print(\"red light detected\")\n",
    "            if x1<zebra[0] and y1<zebra[2]:\n",
    "                image=cv2.rectangle(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            \n",
    "        image=cv2.rectangle(image,(x1,y1),(x2,y2),(255,255,0),2)\n",
    "        cv2.imwrite('vehicle.jpg',roi)\n",
    "        \n",
    "        img=cv2.imread(\"vehicle.jpg\")\n",
    "        results = yolo_predictions(img,net,model,nam)\n",
    "cv2.imshow(\"imagee\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb571d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('results',cv2.WINDOW_KEEPRATIO)\n",
    "cv2.imshow('results',results)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0bd0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vehicle_d(img):\n",
    "    model1 = YOLO(\"veh.pt\") \n",
    "   \n",
    "    cv2.imwrite('frame.jpg',img)\n",
    "    labels=[]\n",
    "    # Process results list\n",
    "    l=[]\n",
    "    model = YOLO(\"numberplate.pt\")  \n",
    "    results = model1('frame.jpg') \n",
    "    image=cv2.imread('frame.jpg')\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.tolist()\n",
    "        classes = result.boxes.cls.tolist()\n",
    "        names = result.names\n",
    "        confidences = result.boxes.conf.tolist()\n",
    "        print(boxes)\n",
    "        for box, cls, conf in zip(boxes, classes, confidences):\n",
    "            x1, y1, x2, y2 = box\n",
    "            print(cls,names[int(cls)],x1,y1,x2,y2)\n",
    "            confidence = conf\n",
    "            detected_class = cls\n",
    "            nam = names[int(cls)]\n",
    "\n",
    "            x1=int(x1)#x\n",
    "            x2=int(x2)#y\n",
    "            y1=int(y1)#w\n",
    "            y2=int(y2)#h\n",
    "            l.append(nam)\n",
    "            roi = image[x2+10:x2+y2+10, x1+10:x1+y1+10]\n",
    "            cv2.imwrite('vehicle.jpg',roi)\n",
    "            imag=cv2.imread(\"vehicle.jpg\")\n",
    "            yolo_predictions(imag,net,model,nam)\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b050aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 1 motorcycle, 2658.1ms\n",
      "Speed: 238.5ms preprocess, 2658.1ms inference, 253.9ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1152.4088134765625, 64.6378402709961, 1477.9307861328125, 280.1433410644531], [1648.298828125, 224.84194946289062, 1733.3382568359375, 314.0312194824219], [0.0, 452.0436096191406, 886.9840087890625, 1080.0]]\n",
      "0.0 auto 1152.4088134765625 64.6378402709961 1477.9307861328125 280.1433410644531\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m----> 2\u001b[0m vehicle_d(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mim7.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 34\u001b[0m, in \u001b[0;36mvehicle_d\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     32\u001b[0m         imag\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvehicle.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m         yolo_predictions(imag,net,model,nam)\n\u001b[1;32m---> 34\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mrectangle(img,(x1,y1),(x2,y2),(\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     35\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLO\u001b[39m\u001b[38;5;124m'\u001b[39m,img)\n\u001b[0;32m     36\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "vehicle_d(\"im7.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ed4c5",
   "metadata": {},
   "source": [
    "### Real Time Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24ea4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 2 motorcycles, 1156.2ms\n",
      "Speed: 15.6ms preprocess, 1156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.8690185546875, 67.34132385253906, 1477.1690673828125, 279.610107421875], [1029.57275390625, 634.0707397460938, 1296.752197265625, 916.0559692382812], [0.0, 459.16259765625, 876.5213623046875, 1080.0], [1820.1910400390625, 271.7037658691406, 1919.848388671875, 453.2034912109375]]\n",
      "0.0 auto 1153.8690185546875 67.34132385253906 1477.1690673828125 279.610107421875\n",
      "4.0 motorcycle 1029.57275390625 634.0707397460938 1296.752197265625 916.0559692382812\n",
      "2.0 bus1 0.0 459.16259765625 876.5213623046875 1080.0\n",
      "4.0 motorcycle 1820.1910400390625 271.7037658691406 1919.848388671875 453.2034912109375\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 3 motorcycles, 1263.7ms\n",
      "Speed: 20.0ms preprocess, 1263.7ms inference, 152.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.8153076171875, 67.39424896240234, 1477.2117919921875, 279.6361083984375], [1030.0369873046875, 637.6021118164062, 1297.203369140625, 916.1515502929688], [0.0, 459.2026062011719, 876.7255859375, 1080.0], [1580.6297607421875, 118.67988586425781, 1774.0986328125, 222.405029296875], [1820.19677734375, 272.0238037109375, 1919.853271484375, 453.23675537109375]]\n",
      "0.0 auto 1153.8153076171875 67.39424896240234 1477.2117919921875 279.6361083984375\n",
      "4.0 motorcycle 1030.0369873046875 637.6021118164062 1297.203369140625 916.1515502929688\n",
      "2.0 bus1 0.0 459.2026062011719 876.7255859375 1080.0\n",
      "4.0 motorcycle 1580.6297607421875 118.67988586425781 1774.0986328125 222.405029296875\n",
      "4.0 motorcycle 1820.19677734375 272.0238037109375 1919.853271484375 453.23675537109375\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 3 motorcycles, 765.6ms\n",
      "Speed: 15.6ms preprocess, 765.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.90478515625, 67.53365325927734, 1477.2557373046875, 279.5535583496094], [1030.6590576171875, 630.4492797851562, 1297.096923828125, 915.9256591796875], [0.0, 459.14715576171875, 877.27197265625, 1080.0], [1578.5126953125, 121.33187866210938, 1774.3084716796875, 222.56137084960938], [1820.2066650390625, 271.7125549316406, 1919.8486328125, 453.1374206542969]]\n",
      "0.0 auto 1153.90478515625 67.53365325927734 1477.2557373046875 279.5535583496094\n",
      "4.0 motorcycle 1030.6590576171875 630.4492797851562 1297.096923828125 915.9256591796875\n",
      "2.0 bus1 0.0 459.14715576171875 877.27197265625 1080.0\n",
      "4.0 motorcycle 1578.5126953125 121.33187866210938 1774.3084716796875 222.56137084960938\n",
      "4.0 motorcycle 1820.2066650390625 271.7125549316406 1919.8486328125 453.1374206542969\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 4 motorcycles, 734.3ms\n",
      "Speed: 0.0ms preprocess, 734.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.7586669921875, 67.36022186279297, 1476.966552734375, 279.7452392578125], [1030.4918212890625, 655.85009765625, 1297.2835693359375, 916.391357421875], [0.0, 458.8130187988281, 877.007568359375, 1080.0], [1820.19873046875, 271.56768798828125, 1919.8538818359375, 453.1582946777344], [1581.4810791015625, 121.68190002441406, 1773.9908447265625, 221.54110717773438], [1351.0426025390625, 715.76806640625, 1918.530029296875, 1078.9051513671875]]\n",
      "0.0 auto 1153.7586669921875 67.36022186279297 1476.966552734375 279.7452392578125\n",
      "4.0 motorcycle 1030.4918212890625 655.85009765625 1297.2835693359375 916.391357421875\n",
      "2.0 bus1 0.0 458.8130187988281 877.007568359375 1080.0\n",
      "4.0 motorcycle 1820.19873046875 271.56768798828125 1919.8538818359375 453.1582946777344\n",
      "4.0 motorcycle 1581.4810791015625 121.68190002441406 1773.9908447265625 221.54110717773438\n",
      "4.0 motorcycle 1351.0426025390625 715.76806640625 1918.530029296875 1078.9051513671875\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 4 motorcycles, 921.8ms\n",
      "Speed: 15.6ms preprocess, 921.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.845458984375, 67.25811767578125, 1476.59326171875, 279.88031005859375], [1030.5101318359375, 632.7301635742188, 1297.4488525390625, 916.2735595703125], [0.0, 458.8587951660156, 877.982421875, 1080.0], [1352.2156982421875, 717.3327026367188, 1919.6923828125, 1078.8477783203125], [1820.0968017578125, 271.2115478515625, 1919.84912109375, 453.17034912109375], [1584.3753662109375, 122.82524871826172, 1774.06494140625, 221.7364501953125]]\n",
      "0.0 auto 1153.845458984375 67.25811767578125 1476.59326171875 279.88031005859375\n",
      "4.0 motorcycle 1030.5101318359375 632.7301635742188 1297.4488525390625 916.2735595703125\n",
      "2.0 bus1 0.0 458.8587951660156 877.982421875 1080.0\n",
      "4.0 motorcycle 1352.2156982421875 717.3327026367188 1919.6923828125 1078.8477783203125\n",
      "4.0 motorcycle 1820.0968017578125 271.2115478515625 1919.84912109375 453.17034912109375\n",
      "4.0 motorcycle 1584.3753662109375 122.82524871826172 1774.06494140625 221.7364501953125\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 2 motorcycles, 812.5ms\n",
      "Speed: 15.6ms preprocess, 812.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.616455078125, 67.33495330810547, 1476.6190185546875, 279.8136901855469], [1030.8175048828125, 639.84228515625, 1298.742919921875, 916.0595703125], [0.0, 458.88623046875, 877.6393432617188, 1080.0], [1820.1627197265625, 271.8509826660156, 1919.8447265625, 453.158203125]]\n",
      "0.0 auto 1153.616455078125 67.33495330810547 1476.6190185546875 279.8136901855469\n",
      "4.0 motorcycle 1030.8175048828125 639.84228515625 1298.742919921875 916.0595703125\n",
      "2.0 bus1 0.0 458.88623046875 877.6393432617188 1080.0\n",
      "4.0 motorcycle 1820.1627197265625 271.8509826660156 1919.8447265625 453.158203125\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 2 motorcycles, 781.2ms\n",
      "Speed: 15.6ms preprocess, 781.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.773193359375, 67.44152069091797, 1476.7413330078125, 279.8212585449219], [1031.0474853515625, 627.6700439453125, 1301.282958984375, 915.4163208007812], [0.0, 458.72784423828125, 877.0101928710938, 1080.0], [1820.1580810546875, 272.1536865234375, 1919.8394775390625, 453.1598205566406]]\n",
      "0.0 auto 1153.773193359375 67.44152069091797 1476.7413330078125 279.8212585449219\n",
      "4.0 motorcycle 1031.0474853515625 627.6700439453125 1301.282958984375 915.4163208007812\n",
      "2.0 bus1 0.0 458.72784423828125 877.0101928710938 1080.0\n",
      "4.0 motorcycle 1820.1580810546875 272.1536865234375 1919.8394775390625 453.1598205566406\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 2 motorcycles, 1066.7ms\n",
      "Speed: 0.0ms preprocess, 1066.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.32373046875, 67.47096252441406, 1476.7265625, 279.70086669921875], [1031.9996337890625, 639.3524780273438, 1299.281005859375, 914.577880859375], [0.0, 458.64031982421875, 876.9483642578125, 1080.0], [1820.218994140625, 272.4900207519531, 1919.8306884765625, 453.1594543457031]]\n",
      "0.0 auto 1153.32373046875 67.47096252441406 1476.7265625 279.70086669921875\n",
      "4.0 motorcycle 1031.9996337890625 639.3524780273438 1299.281005859375 914.577880859375\n",
      "2.0 bus1 0.0 458.64031982421875 876.9483642578125 1080.0\n",
      "4.0 motorcycle 1820.218994140625 272.4900207519531 1919.8306884765625 453.1594543457031\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 4 motorcycles, 1051.5ms\n",
      "Speed: 0.0ms preprocess, 1051.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1156.9996337890625, 65.80415344238281, 1478.364013671875, 277.5867614746094], [1031.6409912109375, 635.2098999023438, 1298.9132080078125, 914.7337036132812], [0.0, 458.6278076171875, 877.232421875, 1080.0], [1605.6826171875, 119.607421875, 1711.552734375, 216.6240234375], [1820.216796875, 272.6265563964844, 1919.825927734375, 453.2015075683594], [1352.2947998046875, 593.0547485351562, 1918.7177734375, 1080.0]]\n",
      "0.0 auto 1156.9996337890625 65.80415344238281 1478.364013671875 277.5867614746094\n",
      "4.0 motorcycle 1031.6409912109375 635.2098999023438 1298.9132080078125 914.7337036132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 bus1 0.0 458.6278076171875 877.232421875 1080.0\n",
      "4.0 motorcycle 1605.6826171875 119.607421875 1711.552734375 216.6240234375\n",
      "4.0 motorcycle 1820.216796875 272.6265563964844 1919.825927734375 453.2015075683594\n",
      "4.0 motorcycle 1352.2947998046875 593.0547485351562 1918.7177734375 1080.0\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 3 motorcycles, 828.1ms\n",
      "Speed: 15.6ms preprocess, 828.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1154.03173828125, 67.483154296875, 1476.2205810546875, 279.6643371582031], [1032.962890625, 633.3519897460938, 1298.974365234375, 914.8632202148438], [0.0, 458.5517578125, 876.9117431640625, 1080.0], [1820.2093505859375, 272.45135498046875, 1919.8292236328125, 453.1754150390625], [1610.1993408203125, 119.47482299804688, 1711.8211669921875, 216.65127563476562]]\n",
      "0.0 auto 1154.03173828125 67.483154296875 1476.2205810546875 279.6643371582031\n",
      "4.0 motorcycle 1032.962890625 633.3519897460938 1298.974365234375 914.8632202148438\n",
      "2.0 bus1 0.0 458.5517578125 876.9117431640625 1080.0\n",
      "4.0 motorcycle 1820.2093505859375 272.45135498046875 1919.8292236328125 453.1754150390625\n",
      "4.0 motorcycle 1610.1993408203125 119.47482299804688 1711.8211669921875 216.65127563476562\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 3 motorcycles, 953.1ms\n",
      "Speed: 15.6ms preprocess, 953.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1153.99072265625, 66.84224700927734, 1476.445068359375, 279.75567626953125], [1032.656982421875, 634.2845458984375, 1299.0247802734375, 914.8486938476562], [0.0, 458.6628723144531, 875.37158203125, 1080.0], [1607.9482421875, 119.88040161132812, 1774.007568359375, 221.01922607421875], [1820.1993408203125, 272.6054382324219, 1919.8497314453125, 453.16357421875]]\n",
      "0.0 auto 1153.99072265625 66.84224700927734 1476.445068359375 279.75567626953125\n",
      "4.0 motorcycle 1032.656982421875 634.2845458984375 1299.0247802734375 914.8486938476562\n",
      "2.0 bus1 0.0 458.6628723144531 875.37158203125 1080.0\n",
      "4.0 motorcycle 1607.9482421875 119.88040161132812 1774.007568359375 221.01922607421875\n",
      "4.0 motorcycle 1820.1993408203125 272.6054382324219 1919.8497314453125 453.16357421875\n",
      "\n",
      "image 1/1 C:\\Users\\Mounika\\number_plate\\yolo_plate\\frame.jpg: 480x800 1 auto, 1 bus1, 3 motorcycles, 1093.7ms\n",
      "Speed: 15.6ms preprocess, 1093.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "[[1154.205078125, 66.04959869384766, 1476.5206298828125, 279.7592468261719], [1032.960693359375, 633.391845703125, 1299.0369873046875, 914.7805786132812], [0.0, 458.5729064941406, 874.7840576171875, 1080.0], [1609.6884765625, 125.27670288085938, 1772.9256591796875, 222.33908081054688], [1820.1865234375, 272.48687744140625, 1919.870849609375, 453.1336669921875]]\n",
      "0.0 auto 1154.205078125 66.04959869384766 1476.5206298828125 279.7592468261719\n",
      "4.0 motorcycle 1032.960693359375 633.391845703125 1299.0369873046875 914.7805786132812\n",
      "2.0 bus1 0.0 458.5729064941406 874.7840576171875 1080.0\n",
      "4.0 motorcycle 1609.6884765625 125.27670288085938 1772.9256591796875 222.33908081054688\n",
      "4.0 motorcycle 1820.1865234375 272.48687744140625 1919.870849609375 453.1336669921875\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "cap = cv2.VideoCapture('./test_images/video1.mov')\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        print('unable to read video')\n",
    "        break\n",
    "    results = vehicle_d(frame)\n",
    "        \n",
    "    \n",
    "            \n",
    "        \n",
    "    cv2.namedWindow('YOLO',cv2.WINDOW_KEEPRATIO)\n",
    "    cv2.imshow('YOLO',results)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d767aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f555dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334df62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b1fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b4192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27b571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35601036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08266d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
